{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f840f379-9b04-48ee-a999-5b702a1ba5ba",
   "metadata": {},
   "source": [
    "# NCLDV filtration\n",
    "\n",
    "NCLDV filtration is an auotmatic tool to filter candidate NCLDVs based on the core gene density.\n",
    "\n",
    "Citation:\n",
    "\n",
    "> \"Genome-resolved year-round dynamics reveal a broad range of giant virus microdiveristy\" In Prep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0970a0-bc39-4b54-a819-a04fa99412d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import seaborn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9b33155-0efc-4d3c-a4a1-669e2aafd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The needed input is a directory wiht .fna files of the bins.\n",
    "wkdir = os.getcwd()\n",
    "\n",
    "# Here, modify the \"test_bins\"\n",
    "# I use a set of 20 bins from a coastal metagenome as the example.\n",
    "bindir = os.path.join(wkdir, \"test_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a1d51b5-5163-4f55-a4cd-9c8c69613918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the prodigal is available in the environment\n",
    "# Use Prodigal -meta for gene call\n",
    "\n",
    "prodigal_output_dir = os.path.join(wkdir, \"prodigal_output\")\n",
    "os.makedirs(prodigal_output_dir, exist_ok=True)\n",
    "\n",
    "for bin_file in os.listdir(bindir):\n",
    "    if bin_file.endswith(\".fna\"):\n",
    "        input_path = os.path.join(bindir, bin_file)\n",
    "        base_name = os.path.splitext(bin_file)[0]\n",
    "        output_faa_path = os.path.join(prodigal_output_dir, f\"{base_name}.faa\")\n",
    "        os.makedirs(os.path.dirname(output_faa_path), exist_ok=True)\n",
    "        cmd = f\"prodigal -i {input_path} -a {output_faa_path} -p meta\"\n",
    "        subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b17882a-6a48-4614-ba51-acc3c29c7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, I've modified the IDs of Prodigal output to align with the bin names.\n",
    "# All protein sequence are saved in \n",
    "outfile1_path = os.path.join(wkdir, \"faa_name_change.csv\")\n",
    "outfile2_path = os.path.join(wkdir, \"all_cds.faa\")\n",
    "\n",
    "with open(outfile1_path, \"w\") as outfile1, open(outfile2_path, \"w\") as outfile2:\n",
    "    for path,dir_list,file_list in os.walk(prodigal_output_dir):\n",
    "        for filename in file_list:\n",
    "            if \"bin\" in filename:\n",
    "                corename = filename.replace('.faa','')\n",
    "                n = 1\n",
    "                with open(os.path.join(prodigal_output_dir, f\"{corename}.faa\"), \"r\") as infile:\n",
    "                    context = infile.read()\n",
    "                    tmp_list = context.split(\">\")\n",
    "                    for tmp in tmp_list:\n",
    "                        if len(tmp) != 0:\n",
    "                            lines = tmp.split(\"\\n\")\n",
    "                            outfile1.write(f\"{lines[0]},{corename}_{n}\\n\")\n",
    "                            outfile2.write(f\"\\n>{corename}_{n}\\n\")\n",
    "                            outfile2.writelines(lines[1:])\n",
    "                            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19b483ae-385e-4f06-8537-c78a6f830e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, I've modified the IDs of Prodigal output to align with the bin names.\n",
    "# All protein sequence are saved in \"all_cds.faa\"\n",
    "# Modification could be checked in \"faa_name_change.csv\"\n",
    "\n",
    "outfile1_path = os.path.join(wkdir, \"faa_name_change.csv\")\n",
    "outfile2_path = os.path.join(wkdir, \"all_cds.faa\")\n",
    "\n",
    "with open(outfile1_path, \"w\") as outfile1, open(outfile2_path, \"w\") as outfile2:\n",
    "    for root, dirs, files in os.walk(prodigal_output_dir):\n",
    "        for filename in filter(lambda f: \"bin\" in f and f.endswith('.faa'), files):\n",
    "            corename = filename.rsplit('.', 1)[0]\n",
    "            with open(os.path.join(root, filename), \"r\") as infile:\n",
    "                for i, record in enumerate(infile.read().strip().split(\">\")[1:], start=1):\n",
    "                    header, *sequence = record.split(\"\\n\")\n",
    "                    outfile1.write(f\"{header},{corename}_{i}\\n\")\n",
    "                    outfile2.write(f\">{corename}_{i}\\n{''.join(sequence)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00c33d3c-39c4-45d8-b37d-55a56df2866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights of NCVOGs, which is determined by the conservation of each NCVOG per NCLDV family.\n",
    "# This is determined by a in-house analysis using reference genomes.\n",
    "ncvog_weights = {\n",
    "    \"NCVOG0022\": 0.9,\n",
    "    \"NCVOG0023\": 1.1,\n",
    "    \"NCVOG0037\": 0.5,\n",
    "    \"NCVOG0038\": 1.1,\n",
    "    \"NCVOG0052\": 0.9,\n",
    "    \"NCVOG0076\": 1.0,\n",
    "    \"NCVOG0236\": 0.8,\n",
    "    \"NCVOG0249\": 1.0,\n",
    "    \"NCVOG0261\": 0.7,\n",
    "    \"NCVOG0262\": 1.0,\n",
    "    \"NCVOG0271\": 0.9,\n",
    "    \"NCVOG0272\": 1.0,\n",
    "    \"NCVOG0273\": 0.8,\n",
    "    \"NCVOG0274\": 0.9,\n",
    "    \"NCVOG0276\": 0.8,\n",
    "    \"NCVOG1060\": 0.6,\n",
    "    \"NCVOG1117\": 0.7,\n",
    "    \"NCVOG1127\": 0.4,\n",
    "    \"NCVOG1164\": 1.0,\n",
    "    \"NCVOG1353\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88cdde-c85e-4768-bc41-ac84c6363290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute hmmsearch for each HMM profile\n",
    "\n",
    "NCVOGs_list = [\n",
    "    \"NCVOG0022\", \"NCVOG0023\", \"NCVOG0037\", \"NCVOG0038\", \"NCVOG0052\", \"NCVOG0076\", \"NCVOG0236\", \"NCVOG0249\",\n",
    "    \"NCVOG0261\", \"NCVOG0262\", \"NCVOG0271\", \"NCVOG0272\", \"NCVOG0273\", \"NCVOG0274\", \"NCVOG0276\", \"NCVOG1060\",\n",
    "    \"NCVOG1117\", \"NCVOG1127\", \"NCVOG1164\", \"NCVOG1353\"\n",
    "]\n",
    "\n",
    "prodigal_output_dir = os.path.join(wkdir, \"hmmout\")\n",
    "os.makedirs(\"hmmout\", exist_ok=True)\n",
    "for ncvo in NCVOGs_list:\n",
    "    hmm_file = os.path.join(f\"hallmark_hmm/{ncvo}.hmm\")\n",
    "    output_file = f\"hmmout/{ncvo}.out\"\n",
    "    cmd = f\"hmmsearch --cpu 10 --notextw --incE 1e-5 --tblout {output_file} {hmm_file} {outfile2_path}\"\n",
    "    subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5eff8ccf-1ad3-4415-bd96-a1942179d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the hmmsearch output and calculate hits\n",
    "# Store in a dictionary\n",
    "info_dict = {dirname.replace(\".faa\",\"\"): [0] * len(NCVOGs_list) for dirname in os.listdir(prodigal_output_dir) if \"bin\" in dirname}\n",
    "\n",
    "for i, ncvo in enumerate(NCVOGs_list):\n",
    "    with open(os.path.join(f\"hmmout/{ncvo}.out\"), \"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "        for line in lines:\n",
    "            if not line.startswith(\"#\"):\n",
    "                for key in info_dict.keys():\n",
    "                    if key in line:\n",
    "                        info_dict[key][i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "339798bf-046b-4190-bccd-fb79d535fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summerize the result and output\n",
    "# 5.75 of Density_index is reccomended as the cut-off for potential NCLDV bins\n",
    "summary_file_path = os.path.join(wkdir, \"summary_core_genes.csv\")\n",
    "with open(summary_file_path, \"w\") as outfile:\n",
    "    outfile.write(\"ID,\" + \",\".join(NCVOGs_list) + \",genome_size,weighted_sum,density_index\\n\")\n",
    "    for binID in info_dict:\n",
    "        genomesize = 0\n",
    "        fastafile = os.path.join(bindir, f\"{binID}.fna\")\n",
    "        with open(fastafile, \"r\") as f:\n",
    "            for line in f:\n",
    "                if not line.startswith(\">\"):\n",
    "                    genomesize += len(line.strip())\n",
    "        # Prepare the list to hold binary values for NCVOG presence/absence\n",
    "        binary_hits = [1 if hit > 0 else 0 for hit in info_dict[binID][:len(NCVOGs_list)]]\n",
    "        weighted_hits = [hit * ncvog_weights[NCVOGs_list[i]] for i, hit in enumerate(binary_hits)]\n",
    "        weighted_sum = sum(weighted_hits)\n",
    "        density_index = weighted_sum/(math.log10(genomesize)-4)\n",
    "        # Append the genome size to the binary hits list\n",
    "        binary_hits_with_genome_size = binary_hits + [genomesize, weighted_sum,density_index]\n",
    "        # Write the binID, binary hit values, and genome size to the file\n",
    "        outfile.write(f\"{binID},\" + \",\".join(map(str, binary_hits_with_genome_size)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5d904-6c6b-417a-91fe-2baf387eb274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
